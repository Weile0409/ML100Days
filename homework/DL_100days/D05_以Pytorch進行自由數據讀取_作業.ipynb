{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作業目的: 熟練自定義collate_fn與sampler進行資料讀取\n",
    "\n",
    "本此作業主要會使用[IMDB](http://ai.stanford.edu/~amaas/data/sentiment/)資料集利用Pytorch的Dataset與DataLoader進行\n",
    "客製化資料讀取。\n",
    "下載後的資料有分成train與test，因為這份作業目的在讀取資料，所以我們取用train部分來進行練習。\n",
    "(請同學先行至IMDB下載資料)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import torch and other required modules\n",
    "import glob\n",
    "import torch\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords') #下載stopwords\n",
    "nltk.download('punkt') #下載word_tokenize需要的corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 探索資料與資料前處理\n",
    "這份作業我們使用test資料中的pos與neg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab length before removing stopwords: 89527\n",
      "vocab length after removing stopwords: 89356\n"
     ]
    }
   ],
   "source": [
    "# 讀取字典，這份字典為review內所有出現的字詞\n",
    "with open('D:/aclImdb_v1/imdb.vocab', 'r',encoding='utf-8') as f:\n",
    "    vocab = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "# 以nltk stopwords移除贅字，過多的贅字無法提供有用的訊息，也可能影響模型的訓練\n",
    "print(f\"vocab length before removing stopwords: {len(vocab)}\")\n",
    "stop_w = set(stopwords.words('english'))\n",
    "vocab = [i for i in vocab if i not in stop_w]\n",
    "print(f\"vocab length after removing stopwords: {len(vocab)}\")\n",
    "\n",
    "# 將字典轉換成dictionary\n",
    "vocab_dic = {word:idx for idx, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('D:aclImdb_v1\\\\test\\\\pos\\\\0_10.txt', 1), ('D:aclImdb_v1\\\\test\\\\pos\\\\10000_7.txt', 1)]\n",
      "Total reviews: 25000\n"
     ]
    }
   ],
   "source": [
    "# 將資料打包成(x, y)配對，其中x為review的檔案路徑，y為正評(1)或負評(0)\n",
    "# 這裡將x以檔案路徑代表的原因是讓同學練習不一次將資料全讀取進來，若電腦記憶體夠大(所有資料檔案沒有很大)\n",
    "# 可以將資料全一次讀取，可以減少在訓練時I/O時間，增加訓練速度\n",
    "import os\n",
    "review_pairs = []\n",
    "for folder,label in [('pos',1),('neg',0)]:\n",
    "    filepaths = glob.glob(os.path.join('D:','aclImdb_v1','test',folder,'*'))\n",
    "    for i in filepaths:\n",
    "        review_pairs.append((i,label))\n",
    "print(review_pairs[:2])\n",
    "print(f\"Total reviews: {len(review_pairs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立Dataset, DataLoader, Sampler與Collate_fn讀取資料\n",
    "這裡我們會需要兩個helper functions，其中一個是讀取資料與清洗資料的函式(load_review)，另外一個是生成詞向量函式\n",
    "(generate_vec)，注意這裡我們用來產生詞向量的方法是單純將文字tokenize(為了使產生的文本長度不同，而不使用BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_review(review_path):\n",
    "    with open(review_path, 'r',encoding='utf-8') as f:\n",
    "        review = f.read()\n",
    " \n",
    "    #移除non-alphabet符號、贅字與tokenize\n",
    "    review = nltk.word_tokenize(re.sub(r'\\W', ' ', review ))\n",
    "    review = [word for word in review if word not in stop_w]\n",
    "    return review\n",
    "\n",
    "def generate_vec(review, vocab_dic):\n",
    "    vec = [vocab_dic[i] for i in review if vocab_dic.get(i)]\n",
    "    return np.asarray(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立客製化dataset\n",
    "\n",
    "class dataset(Dataset):\n",
    "    '''custom dataset to load reviews and labels\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_pairs: list\n",
    "        directory of all review-label pairs\n",
    "    vocab: list\n",
    "        list of vocabularies\n",
    "    '''\n",
    "    def __init__(self, data_dirs, vocab):\n",
    "        self.data_dirs = data_dirs\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_dirs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        review_path, label = self.data_dirs[idx]\n",
    "        gec_vec = generate_vec(load_review(review_path),self.vocab)\n",
    "        return gec_vec,label\n",
    "    \n",
    "\n",
    "#建立客製化collate_fn，將長度不一的文本pad 0 變成相同長度\n",
    "def collate_fn(batch):\n",
    "    corpus, labels = zip(*batch) \n",
    "    ### create pads for corpus ###\n",
    "    lengths = [len(x) for x in corpus]\n",
    "    max_length = max(lengths)\n",
    "    \n",
    "    batch_corpus = []\n",
    "    \n",
    "    for i in range(len(corpus)):\n",
    "        # pad corpus\n",
    "        tmp_pads = torch.zeros(max_length)\n",
    "        tmp_pads[:lengths[i]] = torch.from_numpy(corpus[i])\n",
    "        tmp_pads.view(-1, 1)\n",
    "        batch_corpus.append(tmp_pads.view(1,-1))\n",
    "\n",
    "    return torch.cat(batch_corpus,dim=0), torch.tensor(labels) , torch.tensor(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.2800e+03, 1.2600e+02, 1.3570e+03, 1.8000e+01, 8.2760e+03, 6.3284e+04,\n",
       "          4.2200e+02, 1.5400e+02, 1.4166e+04, 4.3880e+03, 1.6660e+03, 2.2900e+02,\n",
       "          9.6350e+03, 7.5154e+04, 7.5154e+04, 1.8600e+02, 8.3100e+02, 5.7050e+03,\n",
       "          9.6700e+02, 5.6700e+03, 7.3770e+03, 4.5800e+03, 3.8000e+01, 4.1000e+02,\n",
       "          1.6200e+02, 2.5030e+03, 9.0100e+02, 2.9170e+03, 1.3300e+02, 1.3170e+03,\n",
       "          1.6000e+01, 3.9310e+03, 1.8600e+02, 1.0701e+04, 8.5000e+01, 1.6200e+02,\n",
       "          1.9080e+03, 9.0100e+02, 2.5100e+02, 3.3300e+02, 3.8020e+03, 1.9550e+03,\n",
       "          8.2000e+02, 1.3000e+01, 1.8390e+03, 4.3040e+03, 6.3800e+02, 2.9150e+03,\n",
       "          7.5970e+03, 1.2610e+03, 4.3040e+03, 2.8930e+03, 3.5700e+02, 1.5000e+02,\n",
       "          3.3740e+03, 2.2600e+02, 2.7000e+01, 3.4200e+02, 3.0310e+03, 5.3000e+02,\n",
       "          1.6400e+02, 1.7850e+03, 1.6200e+02, 7.5300e+02, 1.2402e+04, 7.5154e+04,\n",
       "          7.5154e+04, 7.2230e+03, 6.8700e+02, 7.4000e+01, 3.4300e+02, 2.3200e+02,\n",
       "          3.3500e+02, 8.9000e+01, 3.9500e+02, 3.3300e+02, 1.8600e+02, 1.8600e+02,\n",
       "          6.6300e+02, 9.0000e+00, 1.4000e+01, 1.3700e+02, 1.2000e+01, 6.7000e+01,\n",
       "          2.8890e+03, 8.6500e+02, 9.6000e+02, 2.5810e+03, 1.0000e+02, 8.4541e+04,\n",
       "          7.5154e+04, 7.5154e+04, 3.2000e+01, 1.4717e+04, 9.8980e+03, 9.0430e+03,\n",
       "          8.0530e+03, 2.7000e+01, 2.8800e+02, 3.3100e+02, 1.2500e+02, 4.9000e+01,\n",
       "          2.2100e+02, 1.7640e+03, 8.3250e+03, 6.7000e+01, 4.5000e+01, 1.8000e+01,\n",
       "          4.2300e+02, 1.3500e+02, 2.4560e+03, 1.8700e+02, 8.0530e+03, 3.6800e+02,\n",
       "          5.6200e+02, 1.1359e+04, 7.1800e+02, 2.4680e+03, 3.2900e+02, 2.6000e+02,\n",
       "          4.9690e+03, 3.6800e+02, 3.1000e+01, 8.3180e+03, 2.3100e+02, 1.8600e+02,\n",
       "          1.8092e+04, 3.8900e+02, 4.9480e+03, 7.5154e+04, 7.5154e+04, 1.8700e+02,\n",
       "          1.9400e+02, 1.1410e+03, 3.7810e+03, 5.8100e+02, 1.2915e+04, 8.6500e+02,\n",
       "          9.6000e+02, 2.1800e+02, 7.8950e+04, 2.1800e+02, 8.1300e+02, 2.0000e+00,\n",
       "          1.3940e+03, 6.5180e+03, 4.9000e+01, 6.8460e+03, 7.5154e+04, 7.5154e+04,\n",
       "          7.1800e+02, 2.6000e+01, 9.0000e+00, 1.4000e+01, 3.1820e+03, 3.2220e+03,\n",
       "          8.2760e+03, 1.0000e+01, 6.8700e+02, 1.9400e+02, 8.4541e+04, 1.2120e+03,\n",
       "          1.6990e+03, 5.9000e+03, 7.9200e+02, 3.4720e+03, 1.9400e+02, 1.6000e+01,\n",
       "          2.3000e+01, 6.4810e+03, 3.6550e+03, 9.6500e+02, 1.7000e+01, 1.4350e+03,\n",
       "          7.5154e+04, 7.5154e+04, 2.8600e+02, 6.2000e+01, 3.1300e+02, 6.0000e+01,\n",
       "          3.0220e+03, 2.2000e+01, 2.5670e+03, 2.9180e+03, 9.6000e+02, 6.0200e+02,\n",
       "          2.1460e+03, 1.0510e+03, 1.0120e+03, 2.4311e+04, 1.9030e+03, 9.6000e+02,\n",
       "          1.4625e+04, 1.0400e+02, 1.4000e+01, 1.1100e+02, 5.0300e+02, 5.8410e+03,\n",
       "          2.2730e+03, 1.7000e+01, 2.2250e+03, 4.0000e+00],\n",
       "         [7.5154e+04, 7.5154e+04, 2.1700e+02, 8.7200e+02, 1.9420e+03, 6.3200e+02,\n",
       "          1.3000e+02, 3.9000e+01, 3.5400e+02, 1.0000e+00, 4.1100e+02, 2.2000e+02,\n",
       "          5.0500e+02, 7.5154e+04, 7.5154e+04, 1.0000e+00, 6.5910e+03, 3.2500e+02,\n",
       "          4.7000e+01, 3.2000e+01, 5.0000e+01, 9.3980e+03, 1.0500e+02, 8.3830e+03,\n",
       "          4.1760e+03, 1.1400e+02, 2.1590e+03, 4.1000e+01, 4.7000e+01, 1.0000e+00,\n",
       "          7.5154e+04, 7.5154e+04, 2.8420e+03, 2.8000e+01, 9.0000e+00, 1.1800e+02,\n",
       "          2.0780e+03, 1.4800e+02, 1.0000e+00, 4.3640e+03, 1.2500e+02, 1.2400e+02,\n",
       "          1.0000e+00, 6.9000e+01, 1.7200e+02, 1.2270e+03, 7.0000e+00, 7.2500e+02,\n",
       "          4.7700e+03, 3.8400e+02, 7.5154e+04, 7.5154e+04, 1.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [6.2470e+03, 2.3400e+02, 1.7570e+03, 2.1000e+01, 2.6000e+01, 5.6000e+01,\n",
       "          1.6300e+02, 3.2000e+02, 2.4000e+01, 1.6020e+03, 1.6000e+01, 4.9340e+03,\n",
       "          1.1200e+02, 1.6354e+04, 2.1000e+01, 2.0660e+03, 1.1496e+04, 7.7880e+03,\n",
       "          4.1630e+03, 6.3000e+01, 1.0450e+03, 3.3990e+03, 1.8700e+02, 8.8040e+03,\n",
       "          3.1000e+01, 4.9000e+02, 1.9380e+03, 1.3167e+04, 3.1000e+01, 4.9000e+02,\n",
       "          1.2163e+04, 1.3228e+04, 2.0000e+01, 1.2400e+02, 1.4920e+03, 4.6140e+03,\n",
       "          2.3740e+03, 9.0000e+00, 2.5100e+02, 3.4595e+04, 1.1609e+04, 1.5030e+03,\n",
       "          7.5154e+04, 7.5154e+04, 2.4000e+01, 9.4000e+01, 1.3180e+03, 6.1400e+02,\n",
       "          9.0000e+00, 2.9290e+03, 1.9770e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [7.5360e+03, 9.7620e+03, 2.1500e+02, 1.3600e+02, 3.2930e+03, 1.8870e+03,\n",
       "          3.6798e+04, 1.0000e+00, 3.6000e+02, 1.3290e+03, 7.3100e+02, 1.2900e+02,\n",
       "          2.8300e+02, 3.3130e+03, 5.1000e+01, 1.8000e+03, 3.6622e+04, 7.5000e+01,\n",
       "          1.0000e+00, 4.0000e+00, 3.2000e+01, 7.1500e+02, 3.0000e+01, 8.0000e+00,\n",
       "          2.8192e+04, 1.8390e+03, 1.0980e+03, 4.8560e+03, 8.0820e+03, 7.1500e+02,\n",
       "          1.6000e+01, 2.1300e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]),\n",
       " tensor([0, 1, 0, 1]),\n",
       " tensor([202,  53,  51,  32]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用Pytorch的RandomSampler來進行indice讀取並建立dataloader\n",
    "custom_dst = dataset(review_pairs, vocab_dic)\n",
    "custom_dataloader = DataLoader(dataset=custom_dst, batch_size=4, sampler=RandomSampler(custom_dst), collate_fn=collate_fn)\n",
    "next(iter(custom_dataloader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
